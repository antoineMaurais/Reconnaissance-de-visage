{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installation des librairies et vérification que CUDA est bien installé"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f28f4a53b69f1a3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hydre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'tensorflow_backend'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend \u001B[38;5;28;01mas\u001B[39;00m K\n\u001B[1;32m----> 2\u001B[0m \u001B[43mK\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensorflow_backend\u001B[49m\u001B[38;5;241m.\u001B[39m_get_available_gpus()\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'keras.backend' has no attribute 'tensorflow_backend'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T14:18:09.220061800Z",
     "start_time": "2024-01-10T14:18:00.705152700Z"
    }
   },
   "id": "e7329e6d995cfc8d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy) (1.26.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install scipy\n",
    "!pip install pillow\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T13:45:16.084752800Z",
     "start_time": "2024-01-10T13:45:09.996685300Z"
    }
   },
   "id": "2288a951a50aa9ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Préparation des Données\n",
    "### 1.1 Organisation des Images : Rangez vos images dans une structure de dossiers appropriée, typiquement un dossier pour chaque classe (homme, femme)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27720ea81e14cb6b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 1. Préparation des Données\n",
    "# Organisation des Images : Rangez vos images dans une structure de dossiers appropriée, typiquement un dossier pour chaque classe (homme, femme).\n",
    "\n",
    "# classifier.py\n",
    "# Permet de classifier les images (homme ou femme) afin de créer des données.\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "# Chemin vers votre fichier JSON\n",
    "fichier_json = '../Data/sorted_by_label.json'\n",
    "\n",
    "# Charger les vecteurs moyens à partir du fichier JSON\n",
    "with open(fichier_json, 'r') as file:\n",
    "    json_content = json.load(file)\n",
    "\n",
    "# Path to the directory where images are stored\n",
    "image_directory_path = Path('../Image/img_align_celeba/img_align_celeba')\n",
    "\n",
    "# Function to display an image by filename\n",
    "def display_image(filename):\n",
    "    try:\n",
    "        image_path = image_directory_path / filename\n",
    "        if not image_path.exists():\n",
    "            print(f\"Image file does not exist: {image_path}\")\n",
    "            return\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening image {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Function to classify images based on user input and create a JSON structure\n",
    "def classify_images(json_data, max_labels=None):\n",
    "    classification_result = {'men': [], 'women': []}\n",
    "    label_count = 0\n",
    "\n",
    "    for label, images in json_data['data'].items():\n",
    "        if max_labels is not None and label_count >= max_labels:\n",
    "            break  # Arrête le traitement après un certain nombre de labels\n",
    "\n",
    "        if images:  # If there are images for the label\n",
    "            # Display the first image of the label\n",
    "            print(images[0])\n",
    "            display_image(images[0])\n",
    "            # Ask the user to classify the label\n",
    "            classification = input(\"Classify the person as a man (m) or a woman (w): \").strip().lower()\n",
    "            if classification == 'm':\n",
    "                classification_result['men'].extend(images)\n",
    "            elif classification == 'w':\n",
    "                classification_result['women'].extend(images)\n",
    "            else:\n",
    "                print(\"Invalid input, skipping this label.\")\n",
    "\n",
    "        label_count += 1\n",
    "\n",
    "    # Write the classification result to a JSON file\n",
    "    with open('classification_result.json', 'w') as outfile:\n",
    "        json.dump(classification_result, outfile, indent=4)\n",
    "\n",
    "    print(\"Classification complete! Results saved to classification_result.json.\")\n",
    "\n",
    "\n",
    "# Exemple d'utilisation : traiter seulement les 100 premiers labels\n",
    "classify_images(json_content, max_labels=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:10:46.543448200Z",
     "start_time": "2024-01-22T11:10:46.536159400Z"
    }
   },
   "id": "ac44a9fa1d74a9a7"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# trierHommeFemme.py\n",
    "# Permet de prendre un fichier json en entré comprennant deux labels (ex: homme et femme), puis il va trier les images dans les bons répertoires.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Chemin du fichier JSON\n",
    "chemin_fichier_json = 'classification_result-testSet.json'\n",
    "\n",
    "# Chemins des dossiers source et cible\n",
    "chemin_dossier_source = '../Image/img_align_celeba/img_align_celeba/'\n",
    "chemin_dossier_hommes = '../Image/testSet/hommes/'\n",
    "chemin_dossier_femmes = '../Image/testSet/femmes/'\n",
    "\n",
    "# Créer les dossiers cibles s'ils n'existent pas\n",
    "os.makedirs(chemin_dossier_hommes, exist_ok=True)\n",
    "os.makedirs(chemin_dossier_femmes, exist_ok=True)\n",
    "\n",
    "# Charger les données JSON\n",
    "with open(chemin_fichier_json, 'r') as fichier:\n",
    "    data = json.load(fichier)\n",
    "\n",
    "# Déplacer les images dans les dossiers correspondants\n",
    "for homme in data['men']:\n",
    "    chemin_source = os.path.join(chemin_dossier_source, homme)\n",
    "    chemin_destination = os.path.join(chemin_dossier_hommes, homme)\n",
    "    shutil.move(chemin_source, chemin_destination)\n",
    "\n",
    "for femme in data['women']:\n",
    "    chemin_source = os.path.join(chemin_dossier_source, femme)\n",
    "    chemin_destination = os.path.join(chemin_dossier_femmes, femme)\n",
    "    shutil.move(chemin_source, chemin_destination)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T11:17:01.456850900Z",
     "start_time": "2024-01-24T11:17:00.264108500Z"
    }
   },
   "id": "22e0de9a61dc85ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Préparation des Données\n",
    "\n",
    "### 1.2 Augmentation des Données : Pour éviter le surapprentissage et améliorer la généralisation, surtout si vous disposez de peu de données, utilisez des techniques d'augmentation d'images (comme la rotation, le zoom, le décalage horizontal/vertical, etc.)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2cf6230b3f81441"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2205 images belonging to 2 classes.\n",
      "Found 2137 images belonging to 2 classes.\n",
      "Found 2058 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Configuration de l'augmentation des données\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         # Normalisation des valeurs de pixels\n",
    "    rotation_range=40,      # Rotation aléatoire de l'image (degrés, 0-180)\n",
    "    width_shift_range=0.2,  # Décalage horizontal aléatoire (fraction de la largeur totale)\n",
    "    height_shift_range=0.2, # Décalage vertical aléatoire (fraction de la hauteur totale)\n",
    "    shear_range=0.2,        # Cisaillement aléatoire\n",
    "    zoom_range=0.2,         # Zoom aléatoire à l'intérieur des images\n",
    "    horizontal_flip=True,   # Retournement aléatoire des images horizontalement\n",
    "    fill_mode='nearest'     # Stratégie pour remplir les pixels nouvellement créés\n",
    ")\n",
    "\n",
    "# Chemin vers le dossier d'entraînement\n",
    "train_dir = '../Image/trainSet/'  # Mettez à jour avec le chemin approprié\n",
    "\n",
    "# Générateur de données d'entraînement\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(178, 218),  # Taille des images après redimensionnement\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 'binary' pour classification binaire, 'categorical' pour multiclasse\n",
    ")\n",
    "\n",
    "# Chemin vers le dossier de validation\n",
    "validation_dir = '../Image/validationSet/'  # Mettez à jour avec le chemin approprié\n",
    "\n",
    "# Générateur de données de validation\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(178, 218),  # Taille des images après redimensionnement\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 'binary' pour classification binaire, 'categorical' pour multiclasse\n",
    ")\n",
    "\n",
    "# Chemin vers le dossier de test\n",
    "test_dir = '../Image/testSet/'  # Mettez à jour avec le chemin approprié\n",
    "\n",
    "# Générateur de données de test\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(178, 218),  # Taille des images après redimensionnement\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 'binary' pour classification binaire, 'categorical' pour multiclasse\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T11:19:30.285480800Z",
     "start_time": "2024-01-24T11:19:30.140635300Z"
    }
   },
   "id": "78e1182684de4722"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Construction du Modèle\n",
    "### 2.1 - Choix du Modèle : Vous pouvez construire un modèle de classification d'images à partir de zéro ou utiliser le transfert d'apprentissage à partir d'un modèle pré-entraîné.\n",
    "### 2.2 - Architecture du Modèle : Définissez l'architecture de votre modèle (couches, neurones, fonctions d'activation, etc.).\n",
    "### 2.3 - Compilation du Modèle : Compilez le modèle avec un optimiseur approprié, une fonction de perte et des métriques.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e32f6ee3f8a0384"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# model-perso.py\n",
    "# 2.1) Création d'un model à partir de zéro\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "### 2.2 - Architecture du Modèle\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(178, 218, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # 1 pour classification binaire (homme/femme)\n",
    "])\n",
    "\n",
    "### 2.3 - Compilation du Modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T10:22:05.859910500Z",
     "start_time": "2024-01-24T10:22:05.594874300Z"
    }
   },
   "id": "b63346aa638a5355"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model-précrée.py\n",
    "\n",
    "# # Utilisation d'un model déjà existant, on vient juste rajouter des couches\n",
    "# \n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D\n",
    "# \n",
    "# # Charger VGG16 sans la partie supérieure (top) - sans les couches de classification\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "# \n",
    "# # Ajouter vos propres couches pour la classification\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# predictions = Dense(1, activation='sigmoid')(x)  # 1 pour classification binaire\n",
    "# \n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# \n",
    "# # Compiler le modèle\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False  # Geler les couches du modèle pré-entraîné\n",
    "# \n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a1efbb19f8e46f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Entraînement du Modèle\n",
    "### 3.1 - Entraînement sur les Données : Entraînez votre modèle sur les données préparées, en utilisant éventuellement la validation croisée pour évaluer sa performance.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d167582a4ba7bb91"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - 60s 860ms/step - loss: 0.6001 - accuracy: 0.6934 - val_loss: 0.5893 - val_accuracy: 0.6856\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - 56s 811ms/step - loss: 0.5844 - accuracy: 0.7057 - val_loss: 0.6618 - val_accuracy: 0.6700\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - 57s 828ms/step - loss: 0.6309 - accuracy: 0.6730 - val_loss: 0.6358 - val_accuracy: 0.6556\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - 57s 820ms/step - loss: 0.6138 - accuracy: 0.6780 - val_loss: 0.6391 - val_accuracy: 0.6413\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - 56s 813ms/step - loss: 0.6047 - accuracy: 0.6821 - val_loss: 0.6677 - val_accuracy: 0.6581\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - 56s 815ms/step - loss: 0.6003 - accuracy: 0.6794 - val_loss: 0.6128 - val_accuracy: 0.6762\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - 56s 816ms/step - loss: 0.5934 - accuracy: 0.6966 - val_loss: 0.6105 - val_accuracy: 0.6675\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - 56s 814ms/step - loss: 0.6030 - accuracy: 0.6875 - val_loss: 0.6314 - val_accuracy: 0.6700\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - 56s 817ms/step - loss: 0.5671 - accuracy: 0.7215 - val_loss: 0.6169 - val_accuracy: 0.6825\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - 56s 818ms/step - loss: 0.5478 - accuracy: 0.7351 - val_loss: 0.7019 - val_accuracy: 0.6444\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - 56s 811ms/step - loss: 0.5613 - accuracy: 0.7120 - val_loss: 0.6402 - val_accuracy: 0.6913\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - 56s 809ms/step - loss: 0.5543 - accuracy: 0.7270 - val_loss: 0.5627 - val_accuracy: 0.7019\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 56s 813ms/step - loss: 0.5536 - accuracy: 0.7161 - val_loss: 0.6507 - val_accuracy: 0.6600\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 56s 812ms/step - loss: 0.5209 - accuracy: 0.7515 - val_loss: 0.5611 - val_accuracy: 0.7038\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 56s 817ms/step - loss: 0.5172 - accuracy: 0.7483 - val_loss: 0.5513 - val_accuracy: 0.7212\n"
     ]
    }
   ],
   "source": [
    "# 3.1) Entraînement sur les données\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=69,  # Nombre de lots à utiliser pendant chaque époque \n",
    "    # si vous avez 2205 images et un batch_size de 32, vous auriez environ 69 steps par époque (2205 / 32 = 68.9)\n",
    "    epochs=15,           # Nombre d'époques pour l'entraînement\n",
    "    # Si vous avez spécifié 100 steps_per_epoch et que vous voulez entraîner le modèle pour 15 époques, votre générateur doit pouvoir fournir (100 * 15 = 1500) lots au total.\n",
    "    validation_data=validation_generator,  # Si vous avez un générateur de validation\n",
    "    validation_steps=50   # Nombre de lots à utiliser pour la validation\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T10:47:29.127057600Z",
     "start_time": "2024-01-24T10:33:22.084663400Z"
    }
   },
   "id": "e037a759ec9f97a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 - Callbacks : Utilisez des callbacks pour des fonctionnalités telles que l'enregistrement des meilleures performances, la réduction du taux d'apprentissage, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1da8b2ad367cf9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.7664\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70063, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 58s 833ms/step - loss: 0.4927 - accuracy: 0.7664 - val_loss: 0.5628 - val_accuracy: 0.7006 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.7519\n",
      "Epoch 2: val_accuracy did not improve from 0.70063\n",
      "69/69 [==============================] - 59s 852ms/step - loss: 0.5112 - accuracy: 0.7519 - val_loss: 0.5891 - val_accuracy: 0.6994 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7633\n",
      "Epoch 3: val_accuracy improved from 0.70063 to 0.72750, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 58s 847ms/step - loss: 0.5032 - accuracy: 0.7633 - val_loss: 0.5364 - val_accuracy: 0.7275 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.7556\n",
      "Epoch 4: val_accuracy improved from 0.72750 to 0.72938, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 59s 849ms/step - loss: 0.4883 - accuracy: 0.7556 - val_loss: 0.5302 - val_accuracy: 0.7294 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.7596\n",
      "Epoch 5: val_accuracy improved from 0.72938 to 0.74000, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 63s 913ms/step - loss: 0.4862 - accuracy: 0.7596 - val_loss: 0.4975 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.7764\n",
      "Epoch 6: val_accuracy did not improve from 0.74000\n",
      "69/69 [==============================] - 57s 823ms/step - loss: 0.4819 - accuracy: 0.7764 - val_loss: 0.5587 - val_accuracy: 0.7163 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.7610\n",
      "Epoch 7: val_accuracy did not improve from 0.74000\n",
      "69/69 [==============================] - 59s 857ms/step - loss: 0.4954 - accuracy: 0.7610 - val_loss: 0.5274 - val_accuracy: 0.7394 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.7791\n",
      "Epoch 8: val_accuracy did not improve from 0.74000\n",
      "69/69 [==============================] - 58s 833ms/step - loss: 0.4792 - accuracy: 0.7791 - val_loss: 0.5235 - val_accuracy: 0.7356 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.7914\n",
      "Epoch 9: val_accuracy improved from 0.74000 to 0.74563, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 60s 870ms/step - loss: 0.4511 - accuracy: 0.7914 - val_loss: 0.4971 - val_accuracy: 0.7456 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.7746\n",
      "Epoch 10: val_accuracy did not improve from 0.74563\n",
      "69/69 [==============================] - 56s 813ms/step - loss: 0.4813 - accuracy: 0.7746 - val_loss: 0.5014 - val_accuracy: 0.7444 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.7810\n",
      "Epoch 11: val_accuracy improved from 0.74563 to 0.75687, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 57s 824ms/step - loss: 0.4532 - accuracy: 0.7810 - val_loss: 0.4900 - val_accuracy: 0.7569 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7859\n",
      "Epoch 12: val_accuracy did not improve from 0.75687\n",
      "69/69 [==============================] - 57s 821ms/step - loss: 0.4567 - accuracy: 0.7859 - val_loss: 0.5222 - val_accuracy: 0.7456 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.7923\n",
      "Epoch 13: val_accuracy did not improve from 0.75687\n",
      "69/69 [==============================] - 57s 822ms/step - loss: 0.4528 - accuracy: 0.7923 - val_loss: 0.5341 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7923\n",
      "Epoch 14: val_accuracy did not improve from 0.75687\n",
      "69/69 [==============================] - 56s 813ms/step - loss: 0.4386 - accuracy: 0.7923 - val_loss: 0.6112 - val_accuracy: 0.6862 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.7959\n",
      "Epoch 15: val_accuracy improved from 0.75687 to 0.76375, saving model to meilleur_modele.h5\n",
      "69/69 [==============================] - 58s 841ms/step - loss: 0.4496 - accuracy: 0.7959 - val_loss: 0.4929 - val_accuracy: 0.7638 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'meilleur_modele.h5',  # Nom du fichier pour sauvegarder le modèle\n",
    "    monitor='val_accuracy', # Métrique à surveiller\n",
    "    verbose=1,             # Afficher des messages détaillés\n",
    "    save_best_only=True,   # Sauvegarder uniquement le meilleur modèle\n",
    "    mode='max'             # Mode 'max' pour la métrique 'accuracy'\n",
    ")\n",
    "\n",
    "# Arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10            # Nombre d'époques sans amélioration après lesquelles l'entraînement est arrêté\n",
    ")\n",
    "\n",
    "# Réduction du taux d'apprentissage\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,            # Facteur de réduction du taux d'apprentissage\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant la réduction\n",
    "    min_lr=0.001           # Taux d'apprentissage minimal\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=69,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T11:03:17.095186500Z",
     "start_time": "2024-01-24T10:48:46.981058200Z"
    }
   },
   "id": "be01ac2f6a8ee5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Évaluation et Ajustement\n",
    "### 4.1 - Évaluer la Performance : Évaluez les performances de votre modèle sur un ensemble de données de test pour vérifier sa généralisation.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2987671fd4d8fee0"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 22s 331ms/step - loss: 0.5080 - accuracy: 0.7614\n",
      "Test accuracy: 0.7614, Test loss: 0.5080\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}, Test loss: {test_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T11:19:59.308218Z",
     "start_time": "2024-01-24T11:19:37.283618600Z"
    }
   },
   "id": "ec603e825492da0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 - Ajustement des Hyperparamètres : Ajustez les hyperparamètres au besoin pour améliorer les performances.\n",
    "\n",
    "Si les performances de votre modèle sur l'ensemble de test ne sont pas satisfaisantes, vous pourriez avoir besoin d'ajuster les hyperparamètres. Les hyperparamètres sont des paramètres qui ne sont pas appris pendant l'entraînement mais qui sont définis à l'avance et qui influencent le comportement et la performance du modèle d'apprentissage. Voici quelques hyperparamètres courants que vous pouvez ajuster :\n",
    "\n",
    "- **Taux d'apprentissage** : C'est un des hyperparamètres les plus importants. S'il est trop élevé, l'entraînement peut ne pas converger ; s'il est trop bas, l'entraînement peut être très lent ou se coincer dans un minimum local.\n",
    "- **Taille des lots** (batch size) : Une plus grande taille de lot peut conduire à une convergence plus stable et plus rapide, mais aussi à une généralisation moins bonne et à des exigences de mémoire plus élevées.\n",
    "- **Architecture du modèle** : Ajouter ou supprimer des couches, changer le nombre de neurones, essayer différentes fonctions d'activation, etc.\n",
    "- **Régularisation** : Techniques comme dropout ou L1/L2 pour prévenir le surajustement.\n",
    "- **Optimiseur** : Changer l'optimiseur (Adam, SGD, RMSprop, etc.) peut affecter la vitesse et la qualité de l'apprentissage.\n",
    "\n",
    "Après avoir ajusté les hyperparamètres, vous devrez réentraîner votre modèle et le réévaluer pour voir si les performances se sont améliorées.\n",
    "\n",
    "N'oubliez pas de noter les performances de chaque configuration pour pouvoir comparer et choisir la meilleure. Des outils comme TensorBoard peuvent être très utiles pour suivre les performances et les hyperparamètres pendant l'entraînement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "479d4f1bf6874a6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Utilisation du Modèle\n",
    "### 5.1 - Sauvegarde du Modèle : Sauvegardez votre modèle entraîné pour une utilisation future."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47ee787742f18b7a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Sauvegarde du modèle complet\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmon_modele.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# Crée un fichier HDF5 'mon_modele.h5'\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle complet\n",
    "model.save('mon_modele.h5')  # Crée un fichier HDF5 'mon_modele.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T07:23:26.029082100Z",
     "start_time": "2024-01-30T07:23:25.830144900Z"
    }
   },
   "id": "b7e95f6dca89ca26"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hydre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hydre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hydre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Chargement du même modèle\n",
    "model = load_model('mon_modele.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T07:23:35.395878700Z",
     "start_time": "2024-01-30T07:23:29.551767600Z"
    }
   },
   "id": "4b725a55e0c00993"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "women , with  53.749531507492065 % certitude\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "\n",
    "# Liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Chargement et prétraitement d'une image\n",
    "img_path = \"../Image/florian.png\"\n",
    "img = image.load_img(img_path, target_size=(178, 218))\n",
    "img_tensor = image.img_to_array(img)  # Convertit l'image en tableau numpy\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)  # Ajoute une dimension pour le lot\n",
    "img_tensor /= 255.  # Normalisation si nécessaire (comme pendant l'entraînement)\n",
    "\n",
    "# Faire la prédiction\n",
    "predictions = model.predict(img_tensor)\n",
    "\n",
    "# Traitez les prédictions ici\n",
    "# Par exemple, pour la classification binaire, vous pouvez utiliser :\n",
    "predicted_class = 'men' if predictions[0] > 0.75 else 'women'\n",
    "print(predicted_class, \", with \", predictions[0][0]*100, \"% certitude\")\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour charger les résultats existants\n",
    "def load_existing_results(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return []  # Retourne une liste vide si le fichier n'existe pas\n",
    "    \n",
    "# Fonction pour vérifier si un résultat existe déjà et le mettre à jour\n",
    "def update_or_add_prediction(filename, predicted_class, confidence, results):\n",
    "    # Recherche d'un résultat existant avec le même nom de fichier\n",
    "    for result in results:\n",
    "        if result['Filename'] == filename:\n",
    "            # Mise à jour du résultat existant\n",
    "            result['PredictedClass'] = predicted_class\n",
    "            result['Confidence'] = confidence\n",
    "            return\n",
    "    # Ajout d'un nouveau résultat si aucun résultat existant n'a été trouvé\n",
    "    results.append({\n",
    "        \"Filename\": filename,\n",
    "        \"PredictedClass\": predicted_class,\n",
    "        \"Confidence\": confidence\n",
    "    })\n",
    "    \n",
    "# Charger les résultats existants\n",
    "results_file = 'prediction_model1.json'\n",
    "existing_results = load_existing_results(results_file)\n",
    "\n",
    "# Mettre à jour ou ajouter un résultat de prédiction\n",
    "update_or_add_prediction(img_path, predicted_class, float(predictions[0][0]), existing_results)\n",
    "\n",
    "# Enregistrement dans un fichier JSON avec les résultats mis à jour\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(existing_results, f, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:11:33.202306Z",
     "start_time": "2024-01-30T10:11:33.148244300Z"
    }
   },
   "id": "b816b920a6e27444"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 - Déploiement du Modèle : Déployez le modèle pour des prédictions en temps réel ou sur de nouvelles données.\n",
    "\n",
    "Le déploiement de votre modèle dépendra de l'environnement dans lequel vous souhaitez l'utiliser. Voici quelques options courantes :\n",
    "\n",
    "- **Application Web** : Vous pouvez déployer votre modèle dans une application web en utilisant des frameworks comme Flask ou Django en Python. L'application recevra des données (par exemple, des images téléchargées par les utilisateurs), les traitera et utilisera le modèle pour faire des prédictions.\n",
    "\n",
    "- **APIs REST** : Vous pouvez créer une API REST qui permet aux utilisateurs d'envoyer des données à votre modèle via des requêtes HTTP et de recevoir des prédictions. Des outils comme TensorFlow Serving, ou des plateformes d'infrastructure comme Google Cloud ML Engine, peuvent faciliter cette tâche.\n",
    "\n",
    "- **Applications Mobiles ou de Bureau** : Vous pouvez intégrer votre modèle dans des applications mobiles ou de bureau. Pour les applications mobiles, TensorFlow Lite peut être utilisé pour convertir votre modèle et le rendre compatible avec les plateformes mobiles.\n",
    "\n",
    "- **Services Cloud** : Vous pouvez également déployer votre modèle sur des plateformes cloud qui offrent des services d'inférence de machine learning, tels que AWS SageMaker, Azure ML ou Google AI Platform.\n",
    "\n",
    "Peu importe la méthode que vous choisissez, vous devrez adapter le format de vos données d'entrée au format attendu par votre modèle, et vous assurer que l'environnement de déploiement a accès à toutes les dépendances nécessaires pour exécuter votre modèle."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90ed063156d50a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c69fdaffd951a37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
