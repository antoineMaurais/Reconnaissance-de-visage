{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installation des librairies et vérification que CUDA est bien installé"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f28f4a53b69f1a3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hydre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install scipy\n",
    "!pip install pillow\n",
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:08:57.947122100Z",
     "start_time": "2024-02-16T23:08:49.139825900Z"
    }
   },
   "id": "ce8ac5fd7c8f22e3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'tensorflow_backend'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend \u001B[38;5;28;01mas\u001B[39;00m K\n\u001B[1;32m----> 2\u001B[0m \u001B[43mK\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensorflow_backend\u001B[49m\u001B[38;5;241m.\u001B[39m_get_available_gpus()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Chemin à ajuster par rapport à votre dataset.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m pathImageCelib \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../Image/img_align_celeba/img_align_celeba\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'keras.backend' has no attribute 'tensorflow_backend'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:09:06.123530400Z",
     "start_time": "2024-02-16T23:09:06.103358800Z"
    }
   },
   "id": "e7329e6d995cfc8d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Chemin à ajuster par rapport à votre dataset.\n",
    "pathImageCelib = '../Image/img_align_celeba/img_align_celeba'\n",
    "\n",
    "pathTestSet = '../Image/testSet'\n",
    "pathTrainSet = '../Image/trainSet'\n",
    "pathValidationSet = '../Image/validationSet'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:11:37.290780Z",
     "start_time": "2024-02-16T23:11:37.277279900Z"
    }
   },
   "id": "314c0adb38d90db0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vérification des GPUs disponible"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99a601f657c9585e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:11:42.229918Z",
     "start_time": "2024-02-16T23:11:42.219389600Z"
    }
   },
   "id": "682e44b653fc4db6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Préparation des Données\n",
    "### 1.1 Organisation des Images : Rangez vos images dans une structure de dossiers appropriée, typiquement un dossier pour chaque classe (homme, femme)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27720ea81e14cb6b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000023.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000023.jpg\n",
      "Invalid input, skipping this label.\n",
      "016188.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\016188.jpg\n",
      "Invalid input, skipping this label.\n",
      "003029.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\003029.jpg\n",
      "Invalid input, skipping this label.\n",
      "008268.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\008268.jpg\n",
      "Invalid input, skipping this label.\n",
      "000456.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000456.jpg\n",
      "Invalid input, skipping this label.\n",
      "002617.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002617.jpg\n",
      "Invalid input, skipping this label.\n",
      "002065.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002065.jpg\n",
      "Invalid input, skipping this label.\n",
      "003089.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\003089.jpg\n",
      "Invalid input, skipping this label.\n",
      "010959.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\010959.jpg\n",
      "Invalid input, skipping this label.\n",
      "002307.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002307.jpg\n",
      "Invalid input, skipping this label.\n",
      "063458.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\063458.jpg\n",
      "Invalid input, skipping this label.\n",
      "002486.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002486.jpg\n",
      "Invalid input, skipping this label.\n",
      "000077.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000077.jpg\n",
      "Invalid input, skipping this label.\n",
      "032486.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\032486.jpg\n",
      "Invalid input, skipping this label.\n",
      "011256.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\011256.jpg\n",
      "Invalid input, skipping this label.\n",
      "016740.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\016740.jpg\n",
      "Invalid input, skipping this label.\n",
      "003677.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\003677.jpg\n",
      "Invalid input, skipping this label.\n",
      "162774.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\162774.jpg\n",
      "Invalid input, skipping this label.\n",
      "004319.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004319.jpg\n",
      "Invalid input, skipping this label.\n",
      "004538.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004538.jpg\n",
      "Invalid input, skipping this label.\n",
      "003039.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\003039.jpg\n",
      "Invalid input, skipping this label.\n",
      "000481.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000481.jpg\n",
      "Invalid input, skipping this label.\n",
      "004488.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004488.jpg\n",
      "Invalid input, skipping this label.\n",
      "001505.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001505.jpg\n",
      "Invalid input, skipping this label.\n",
      "005346.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\005346.jpg\n",
      "Invalid input, skipping this label.\n",
      "002162.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002162.jpg\n",
      "Invalid input, skipping this label.\n",
      "001784.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001784.jpg\n",
      "Invalid input, skipping this label.\n",
      "000835.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000835.jpg\n",
      "Invalid input, skipping this label.\n",
      "004379.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004379.jpg\n",
      "Invalid input, skipping this label.\n",
      "020646.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\020646.jpg\n",
      "Invalid input, skipping this label.\n",
      "009309.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\009309.jpg\n",
      "Invalid input, skipping this label.\n",
      "000605.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000605.jpg\n",
      "Invalid input, skipping this label.\n",
      "000492.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000492.jpg\n",
      "Invalid input, skipping this label.\n",
      "011199.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\011199.jpg\n",
      "Invalid input, skipping this label.\n",
      "001265.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001265.jpg\n",
      "Invalid input, skipping this label.\n",
      "021995.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\021995.jpg\n",
      "Invalid input, skipping this label.\n",
      "002329.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002329.jpg\n",
      "Invalid input, skipping this label.\n",
      "028286.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\028286.jpg\n",
      "Invalid input, skipping this label.\n",
      "002270.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002270.jpg\n",
      "Invalid input, skipping this label.\n",
      "009551.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\009551.jpg\n",
      "Invalid input, skipping this label.\n",
      "010700.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\010700.jpg\n",
      "Invalid input, skipping this label.\n",
      "007906.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\007906.jpg\n",
      "Invalid input, skipping this label.\n",
      "004683.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004683.jpg\n",
      "Invalid input, skipping this label.\n",
      "040169.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\040169.jpg\n",
      "Invalid input, skipping this label.\n",
      "005122.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\005122.jpg\n",
      "Invalid input, skipping this label.\n",
      "004234.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004234.jpg\n",
      "Invalid input, skipping this label.\n",
      "002733.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002733.jpg\n",
      "Invalid input, skipping this label.\n",
      "012555.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\012555.jpg\n",
      "Invalid input, skipping this label.\n",
      "002550.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002550.jpg\n",
      "Invalid input, skipping this label.\n",
      "007145.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\007145.jpg\n",
      "Invalid input, skipping this label.\n",
      "008964.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\008964.jpg\n",
      "Invalid input, skipping this label.\n",
      "010653.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\010653.jpg\n",
      "Invalid input, skipping this label.\n",
      "001171.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001171.jpg\n",
      "Invalid input, skipping this label.\n",
      "001981.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001981.jpg\n",
      "Invalid input, skipping this label.\n",
      "013204.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\013204.jpg\n",
      "Invalid input, skipping this label.\n",
      "163136.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\163136.jpg\n",
      "Invalid input, skipping this label.\n",
      "004198.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004198.jpg\n",
      "Invalid input, skipping this label.\n",
      "012500.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\012500.jpg\n",
      "Invalid input, skipping this label.\n",
      "000129.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000129.jpg\n",
      "Invalid input, skipping this label.\n",
      "023854.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\023854.jpg\n",
      "Invalid input, skipping this label.\n",
      "001352.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001352.jpg\n",
      "Invalid input, skipping this label.\n",
      "163164.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\163164.jpg\n",
      "Invalid input, skipping this label.\n",
      "016486.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\016486.jpg\n",
      "Invalid input, skipping this label.\n",
      "011839.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\011839.jpg\n",
      "Invalid input, skipping this label.\n",
      "000854.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000854.jpg\n",
      "Invalid input, skipping this label.\n",
      "002438.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002438.jpg\n",
      "Invalid input, skipping this label.\n",
      "000932.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000932.jpg\n",
      "Invalid input, skipping this label.\n",
      "016684.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\016684.jpg\n",
      "Invalid input, skipping this label.\n",
      "001593.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001593.jpg\n",
      "Invalid input, skipping this label.\n",
      "021779.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\021779.jpg\n",
      "Invalid input, skipping this label.\n",
      "009590.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\009590.jpg\n",
      "Invalid input, skipping this label.\n",
      "022783.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\022783.jpg\n",
      "Invalid input, skipping this label.\n",
      "001745.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001745.jpg\n",
      "Invalid input, skipping this label.\n",
      "165513.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\165513.jpg\n",
      "Invalid input, skipping this label.\n",
      "004466.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004466.jpg\n",
      "Invalid input, skipping this label.\n",
      "170596.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\170596.jpg\n",
      "Invalid input, skipping this label.\n",
      "013306.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\013306.jpg\n",
      "Invalid input, skipping this label.\n",
      "000171.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000171.jpg\n",
      "Invalid input, skipping this label.\n",
      "004556.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004556.jpg\n",
      "Invalid input, skipping this label.\n",
      "010998.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\010998.jpg\n",
      "Invalid input, skipping this label.\n",
      "006514.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\006514.jpg\n",
      "Invalid input, skipping this label.\n",
      "005373.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\005373.jpg\n",
      "Invalid input, skipping this label.\n",
      "004643.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004643.jpg\n",
      "Invalid input, skipping this label.\n",
      "006901.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\006901.jpg\n",
      "Invalid input, skipping this label.\n",
      "007222.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\007222.jpg\n",
      "Invalid input, skipping this label.\n",
      "001908.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\001908.jpg\n",
      "Invalid input, skipping this label.\n",
      "000567.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\000567.jpg\n",
      "Invalid input, skipping this label.\n",
      "006183.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\006183.jpg\n",
      "Invalid input, skipping this label.\n",
      "002409.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002409.jpg\n",
      "Invalid input, skipping this label.\n",
      "008691.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\008691.jpg\n",
      "Invalid input, skipping this label.\n",
      "002204.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\002204.jpg\n",
      "Invalid input, skipping this label.\n",
      "007494.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\007494.jpg\n",
      "Invalid input, skipping this label.\n",
      "021648.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\021648.jpg\n",
      "Invalid input, skipping this label.\n",
      "005110.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\005110.jpg\n",
      "Invalid input, skipping this label.\n",
      "011073.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\011073.jpg\n",
      "Invalid input, skipping this label.\n",
      "004849.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\004849.jpg\n",
      "Invalid input, skipping this label.\n",
      "162839.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\162839.jpg\n",
      "Invalid input, skipping this label.\n",
      "005390.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\005390.jpg\n",
      "Invalid input, skipping this label.\n",
      "021720.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\021720.jpg\n",
      "Invalid input, skipping this label.\n",
      "163099.jpg\n",
      "Image file does not exist: ..\\Image\\img_align_celeba\\img_align_celeba\\163099.jpg\n",
      "Invalid input, skipping this label.\n",
      "Classification complete! Results saved to classification_result.json.\n"
     ]
    }
   ],
   "source": [
    "# 1. Préparation des Données\n",
    "# Organisation des Images : Rangez vos images dans une structure de dossiers appropriée, typiquement un dossier pour chaque classe (homme, femme).\n",
    "\n",
    "# classifier.py\n",
    "# Permet de classifier les images (homme ou femme) afin de créer des données.\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "# Chemin vers votre fichier JSON\n",
    "fichier_json = '../Data/sorted_by_label.json'\n",
    "\n",
    "# Charger les vecteurs moyens à partir du fichier JSON\n",
    "with open(fichier_json, 'r') as file:\n",
    "    json_content = json.load(file)\n",
    "\n",
    "# Path to the directory where images are stored\n",
    "image_directory_path = Path(pathImageCelib)\n",
    "\n",
    "# Function to display an image by filename\n",
    "def display_image(filename):\n",
    "    try:\n",
    "        image_path = image_directory_path / filename\n",
    "        if not image_path.exists():\n",
    "            print(f\"Image file does not exist: {image_path}\")\n",
    "            return\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening image {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Function to classify images based on user input and create a JSON structure\n",
    "def classify_images(json_data, max_labels=None):\n",
    "    classification_result = {'men': [], 'women': []}\n",
    "    label_count = 0\n",
    "\n",
    "    for label, images in json_data['data'].items():\n",
    "        if max_labels is not None and label_count >= max_labels:\n",
    "            break  # Arrête le traitement après un certain nombre de labels\n",
    "\n",
    "        if images:  # If there are images for the label\n",
    "            # Display the first image of the label\n",
    "            print(images[0])\n",
    "            display_image(images[0])\n",
    "            # Ask the user to classify the label\n",
    "            classification = input(\"Classify the person as a man (m) or a woman (w): \").strip().lower()\n",
    "            if classification == 'm':\n",
    "                classification_result['men'].extend(images)\n",
    "            elif classification == 'w':\n",
    "                classification_result['women'].extend(images)\n",
    "            else:\n",
    "                print(\"Invalid input, skipping this label.\")\n",
    "\n",
    "        label_count += 1\n",
    "\n",
    "    # Write the classification result to a JSON file\n",
    "    with open('classification_result.json', 'w') as outfile:\n",
    "        json.dump(classification_result, outfile, indent=4)\n",
    "\n",
    "    print(\"Classification complete! Results saved to classification_result.json.\")\n",
    "\n",
    "\n",
    "# Exemple d'utilisation : traiter seulement les 100 premiers labels\n",
    "classify_images(json_content, max_labels=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:12:13.308311Z",
     "start_time": "2024-02-16T23:11:45.087501900Z"
    }
   },
   "id": "ac44a9fa1d74a9a7"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'classification_result-testSet.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 21\u001B[0m\n\u001B[0;32m     18\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(chemin_dossier_femmes, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Charger les données JSON\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchemin_fichier_json\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fichier:\n\u001B[0;32m     22\u001B[0m     data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(fichier)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Déplacer les images dans les dossiers correspondants\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[1;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'classification_result-testSet.json'"
     ]
    }
   ],
   "source": [
    "# trierHommeFemme.py\n",
    "# Permet de prendre un fichier json en entré comprennant deux labels (ex: homme et femme), puis il va trier les images dans les bons répertoires.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Chemin du fichier JSON\n",
    "chemin_fichier_json = 'classification_result-testSet.json'\n",
    "\n",
    "# Chemins des dossiers source et cible\n",
    "chemin_dossier_source = pathImageCelib\n",
    "chemin_dossier_hommes = pathTestSet+'/hommes/'\n",
    "chemin_dossier_femmes = pathTestSet+'/femmes/'\n",
    "\n",
    "# Créer les dossiers cibles s'ils n'existent pas\n",
    "os.makedirs(chemin_dossier_hommes, exist_ok=True)\n",
    "os.makedirs(chemin_dossier_femmes, exist_ok=True)\n",
    "\n",
    "# Charger les données JSON\n",
    "with open(chemin_fichier_json, 'r') as fichier:\n",
    "    data = json.load(fichier)\n",
    "\n",
    "# Déplacer les images dans les dossiers correspondants\n",
    "for homme in data['men']:\n",
    "    chemin_source = os.path.join(chemin_dossier_source, homme)\n",
    "    chemin_destination = os.path.join(chemin_dossier_hommes, homme)\n",
    "    shutil.move(chemin_source, chemin_destination)\n",
    "\n",
    "for femme in data['women']:\n",
    "    chemin_source = os.path.join(chemin_dossier_source, femme)\n",
    "    chemin_destination = os.path.join(chemin_dossier_femmes, femme)\n",
    "    shutil.move(chemin_source, chemin_destination)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T23:13:20.357310800Z",
     "start_time": "2024-02-16T23:13:20.297817300Z"
    }
   },
   "id": "22e0de9a61dc85ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Préparation des Données\n",
    "\n",
    "### 1.2 Augmentation des Données : Pour éviter le surapprentissage et améliorer la généralisation, surtout si vous disposez de peu de données, utilisez des techniques d'augmentation d'images (comme la rotation, le zoom, le décalage horizontal/vertical, etc.)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2cf6230b3f81441"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Configuration de l'augmentation des données\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         # Normalisation des valeurs de pixels\n",
    "    rotation_range=40,      # Rotation aléatoire de l'image (degrés, 0-180)\n",
    "    width_shift_range=0.2,  # Décalage horizontal aléatoire (fraction de la largeur totale)\n",
    "    height_shift_range=0.2, # Décalage vertical aléatoire (fraction de la hauteur totale)\n",
    "    shear_range=0.2,        # Cisaillement aléatoire\n",
    "    zoom_range=0.2,         # Zoom aléatoire à l'intérieur des images\n",
    "    horizontal_flip=True,   # Retournement aléatoire des images horizontalement\n",
    "    fill_mode='nearest'     # Stratégie pour remplir les pixels nouvellement créés\n",
    ")\n",
    "\n",
    "# Chemin vers le dossier d'entraînement\n",
    "train_dir = pathTrainSet+'/'  # Mettez à jour avec le chemin approprié\n",
    "\n",
    "# Générateur de données d'entraînement\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(178, 218),  # Taille des images après redimensionnement\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 'binary' pour classification binaire, 'categorical' pour multiclasse\n",
    ")\n",
    "\n",
    "# Chemin vers le dossier de validation\n",
    "validation_dir = pathValidationSet+'/'  # Mettez à jour avec le chemin approprié\n",
    "\n",
    "# Générateur de données de validation\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(178, 218),  # Taille des images après redimensionnement\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 'binary' pour classification binaire, 'categorical' pour multiclasse\n",
    ")\n",
    "\n",
    "# Chemin vers le dossier de test\n",
    "test_dir = pathTestSet+'/'  # Mettez à jour avec le chemin approprié\n",
    "\n",
    "# Générateur de données de test\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(178, 218),  # Taille des images après redimensionnement\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 'binary' pour classification binaire, 'categorical' pour multiclasse\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "78e1182684de4722"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Construction du Modèle\n",
    "### 2.1 - Choix du Modèle : Vous pouvez construire un modèle de classification d'images à partir de zéro ou utiliser le transfert d'apprentissage à partir d'un modèle pré-entraîné.\n",
    "### 2.2 - Architecture du Modèle : Définissez l'architecture de votre modèle (couches, neurones, fonctions d'activation, etc.).\n",
    "### 2.3 - Compilation du Modèle : Compilez le modèle avec un optimiseur approprié, une fonction de perte et des métriques.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e32f6ee3f8a0384"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model-perso.py\n",
    "# 2.1) Création d'un model à partir de zéro\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "### 2.2 - Architecture du Modèle\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(178, 218, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # 1 pour classification binaire (homme/femme)\n",
    "])\n",
    "\n",
    "### 2.3 - Compilation du Modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b63346aa638a5355"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model-précrée.py\n",
    "\n",
    "# # Utilisation d'un model déjà existant, on vient juste rajouter des couches\n",
    "# \n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D\n",
    "# \n",
    "# # Charger VGG16 sans la partie supérieure (top) - sans les couches de classification\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "# \n",
    "# # Ajouter vos propres couches pour la classification\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# predictions = Dense(1, activation='sigmoid')(x)  # 1 pour classification binaire\n",
    "# \n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# \n",
    "# # Compiler le modèle\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False  # Geler les couches du modèle pré-entraîné\n",
    "# \n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a1efbb19f8e46f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Entraînement du Modèle\n",
    "### 3.1 - Entraînement sur les Données : Entraînez votre modèle sur les données préparées, en utilisant éventuellement la validation croisée pour évaluer sa performance.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d167582a4ba7bb91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3.1) Entraînement sur les données\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=69,  # Nombre de lots à utiliser pendant chaque époque \n",
    "    # si vous avez 2205 images et un batch_size de 32, vous auriez environ 69 steps par époque (2205 / 32 = 68.9)\n",
    "    epochs=15,           # Nombre d'époques pour l'entraînement\n",
    "    # Si vous avez spécifié 100 steps_per_epoch et que vous voulez entraîner le modèle pour 15 époques, votre générateur doit pouvoir fournir (100 * 15 = 1500) lots au total.\n",
    "    validation_data=validation_generator,  # Si vous avez un générateur de validation\n",
    "    validation_steps=50   # Nombre de lots à utiliser pour la validation\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e037a759ec9f97a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 - Callbacks : Utilisez des callbacks pour des fonctionnalités telles que l'enregistrement des meilleures performances, la réduction du taux d'apprentissage, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1da8b2ad367cf9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'meilleur_modele.h5',  # Nom du fichier pour sauvegarder le modèle\n",
    "    monitor='val_accuracy', # Métrique à surveiller\n",
    "    verbose=1,             # Afficher des messages détaillés\n",
    "    save_best_only=True,   # Sauvegarder uniquement le meilleur modèle\n",
    "    mode='max'             # Mode 'max' pour la métrique 'accuracy'\n",
    ")\n",
    "\n",
    "# Arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10            # Nombre d'époques sans amélioration après lesquelles l'entraînement est arrêté\n",
    ")\n",
    "\n",
    "# Réduction du taux d'apprentissage\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,            # Facteur de réduction du taux d'apprentissage\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant la réduction\n",
    "    min_lr=0.001           # Taux d'apprentissage minimal\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=69,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "be01ac2f6a8ee5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Évaluation et Ajustement\n",
    "### 4.1 - Évaluer la Performance : Évaluez les performances de votre modèle sur un ensemble de données de test pour vérifier sa généralisation.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2987671fd4d8fee0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}, Test loss: {test_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ec603e825492da0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 - Ajustement des Hyperparamètres : Ajustez les hyperparamètres au besoin pour améliorer les performances.\n",
    "\n",
    "Si les performances de votre modèle sur l'ensemble de test ne sont pas satisfaisantes, vous pourriez avoir besoin d'ajuster les hyperparamètres. Les hyperparamètres sont des paramètres qui ne sont pas appris pendant l'entraînement mais qui sont définis à l'avance et qui influencent le comportement et la performance du modèle d'apprentissage. Voici quelques hyperparamètres courants que vous pouvez ajuster :\n",
    "\n",
    "- **Taux d'apprentissage** : C'est un des hyperparamètres les plus importants. S'il est trop élevé, l'entraînement peut ne pas converger ; s'il est trop bas, l'entraînement peut être très lent ou se coincer dans un minimum local.\n",
    "- **Taille des lots** (batch size) : Une plus grande taille de lot peut conduire à une convergence plus stable et plus rapide, mais aussi à une généralisation moins bonne et à des exigences de mémoire plus élevées.\n",
    "- **Architecture du modèle** : Ajouter ou supprimer des couches, changer le nombre de neurones, essayer différentes fonctions d'activation, etc.\n",
    "- **Régularisation** : Techniques comme dropout ou L1/L2 pour prévenir le surajustement.\n",
    "- **Optimiseur** : Changer l'optimiseur (Adam, SGD, RMSprop, etc.) peut affecter la vitesse et la qualité de l'apprentissage.\n",
    "\n",
    "Après avoir ajusté les hyperparamètres, vous devrez réentraîner votre modèle et le réévaluer pour voir si les performances se sont améliorées.\n",
    "\n",
    "N'oubliez pas de noter les performances de chaque configuration pour pouvoir comparer et choisir la meilleure. Des outils comme TensorBoard peuvent être très utiles pour suivre les performances et les hyperparamètres pendant l'entraînement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "479d4f1bf6874a6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Utilisation du Modèle\n",
    "### 5.1 - Sauvegarde du Modèle : Sauvegardez votre modèle entraîné pour une utilisation future."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47ee787742f18b7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle complet\n",
    "model.save('mon_modele.h5')  # Crée un fichier HDF5 'mon_modele.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b7e95f6dca89ca26"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "women , with  99.99974210877554 % probability\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import json\n",
    "\n",
    "\n",
    "# Chargement du même modèle\n",
    "model = load_model('mon_modele.h5')\n",
    "\n",
    "# Liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Chargement et prétraitement d'une image\n",
    "img_path = \"../Image/2024_ldiraiso.jpg\"\n",
    "img = image.load_img(img_path, target_size=(178, 218))\n",
    "img_tensor = image.img_to_array(img)  # Convertit l'image en tableau numpy\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)  # Ajoute une dimension pour le lot\n",
    "img_tensor /= 255.  # Normalisation si nécessaire (comme pendant l'entraînement)\n",
    "\n",
    "# Faire la prédiction\n",
    "predictions = model.predict(img_tensor)\n",
    "\n",
    "# Traiter les prédictions\n",
    "if predictions[0] > 0.75 :\n",
    "    predicted_class = 'men'\n",
    "    print(predicted_class, \", with \", predictions[0][0]*100, \"% probability\")\n",
    "else :\n",
    "    predicted_class = 'women'\n",
    "    print(predicted_class, \", with \", 100 - predictions[0][0]*100, \"% probability\")\n",
    "\n",
    "# Fonction pour charger les résultats existants\n",
    "def load_existing_results(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return []  # Retourne une liste vide si le fichier n'existe pas\n",
    "    \n",
    "# Fonction pour vérifier si un résultat existe déjà et le mettre à jour\n",
    "def update_or_add_prediction(filename, predicted_class, confidence, results):\n",
    "    # Recherche d'un résultat existant avec le même nom de fichier\n",
    "    for result in results:\n",
    "        if result['Filename'] == filename:\n",
    "            # Mise à jour du résultat existant\n",
    "            result['PredictedClass'] = predicted_class\n",
    "            result['Confidence'] = confidence\n",
    "            return\n",
    "    # Ajout d'un nouveau résultat si aucun résultat existant n'a été trouvé\n",
    "    results.append({\n",
    "        \"Filename\": filename,\n",
    "        \"PredictedClass\": predicted_class,\n",
    "        \"Confidence\": confidence\n",
    "    })\n",
    "    \n",
    "# Charger les résultats existants\n",
    "results_file = 'prediction_model1.json'\n",
    "existing_results = load_existing_results(results_file)\n",
    "\n",
    "# Mettre à jour ou ajouter un résultat de prédiction\n",
    "update_or_add_prediction(img_path, predicted_class, float(predictions[0][0]), existing_results)\n",
    "\n",
    "# Enregistrement dans un fichier JSON avec les résultats mis à jour\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(existing_results, f, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T20:57:29.171053400Z",
     "start_time": "2024-02-14T20:57:27.143311900Z"
    }
   },
   "id": "b816b920a6e27444"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plus le résultat se rapproche de 100 %, plus la probabilité que ce soit un homme est élevé. \n",
    "À l'inverse, plus le résultat se rapproche de 0%, plus la probabilité d'être un homme est faible, et donc celle d'être une femme est élevé.\n",
    "\n",
    "Afin de mieux présenter le résultat, je soustrais le résultat à 100 dans le cas où le programme détecterait que c'est une femme, ce qui me donne aussi un pourcentage de certitude."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf778605c413607c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 - Déploiement du Modèle : Déployez le modèle pour des prédictions en temps réel ou sur de nouvelles données.\n",
    "\n",
    "- **Application Web** : Nous avons créé une application en React afin d'afficher nos résultats et pouvoir les comparer plus facilement. \n",
    "\n",
    "Amélioration : On pourrait améliorer l'application afin d'afficher différents schémas qui nous aideraient à évaluer le modèle.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90ed063156d50a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T20:50:56.028242900Z",
     "start_time": "2024-02-14T20:50:55.999509Z"
    }
   },
   "id": "6c69fdaffd951a37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
